{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8da008b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_diabetes\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83760b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "496ad569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_summary_info(df):\n",
    "    \"\"\"\n",
    "    Extract summary information from original DataFrame,\n",
    "    including numeric mean/std and categorical label probabilities.\n",
    "\n",
    "    Returns a dict:\n",
    "    {\n",
    "        'col_name': {\n",
    "            'type': 'numeric' or 'categorical',\n",
    "            'mean': float,           # numeric only\n",
    "            'std': float,            # numeric only\n",
    "            'labels': [str, ...],    # categorical only\n",
    "            'probs': [float, ...]    # categorical only, sum to 1\n",
    "        },\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    summary = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            # Numeric column summary\n",
    "            mean = df[col].mean()\n",
    "            std = df[col].std()\n",
    "            summary[col] = {\n",
    "                'type': 'numeric',\n",
    "                'mean': mean,\n",
    "                'std': std if std > 0 else 1e-6  # avoid zero std for sampling\n",
    "            }\n",
    "        else:\n",
    "            # Categorical column summary: get normalized value counts\n",
    "            counts = df[col].value_counts(normalize=True, dropna=False)\n",
    "            labels = counts.index.tolist()\n",
    "            probs = counts.values.tolist()\n",
    "            summary[col] = {\n",
    "                'type': 'categorical',\n",
    "                'labels': labels,\n",
    "                'probs': probs\n",
    "            }\n",
    "\n",
    "    return summary\n",
    "\n",
    "def generate_synthetic_from_summary(summary_info, n):\n",
    "    \"\"\"\n",
    "    Generate synthetic data from extracted summary info.\n",
    "\n",
    "    Parameters:\n",
    "    - summary_info: dict produced by extract_summary_info\n",
    "    - n: number of rows to generate\n",
    "\n",
    "    Returns:\n",
    "    - synthetic_df: pandas DataFrame with synthetic data\n",
    "    \"\"\"\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    for col, info in summary_info.items():\n",
    "        if info['type'] == 'numeric':\n",
    "            mean = info['mean']\n",
    "            std = info['std']\n",
    "            # Sample from normal distribution\n",
    "            samples = np.random.normal(loc=mean, scale=std, size=n)\n",
    "            data[col] = samples\n",
    "        elif info['type'] == 'categorical':\n",
    "            labels = info['labels']\n",
    "            probs = info['probs']\n",
    "            samples = np.random.choice(labels, size=n, p=probs)\n",
    "            data[col] = samples\n",
    "        else:\n",
    "            data[col] = [np.nan] * n\n",
    "\n",
    "    synthetic_df = pd.DataFrame(data)\n",
    "    return synthetic_df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ebda58fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn version: 1.7.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(\"Scikit-learn version:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d54b985a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (features): (100, 5)\n",
      "Shape of Y (targets): (100, 10)\n",
      "\n",
      "First 5 rows of X (features):\n",
      " [[12.  9. 10. 12. 13.]\n",
      " [13.  8. 11. 12.  6.]\n",
      " [16.  8. 10. 12.  4.]\n",
      " [ 9.  9.  7.  9. 18.]\n",
      " [13.  8. 11.  8. 10.]]\n",
      "\n",
      "First 5 rows of Y (targets):\n",
      " [[0 1 0 0 0 1 0 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 0 0 0 1 1 1]\n",
      " [1 1 1 0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "import numpy as np\n",
    "\n",
    "# Define parameters for the synthetic dataset\n",
    "n_samples = 100  # Number of samples (data points)\n",
    "n_features = 5  # Total number of features\n",
    "n_classes = 10  # Number of possible classes/labels\n",
    "n_labels = 4  # Average number of labels per sample\n",
    "\n",
    "# Generate the dataset (remove n_informative, n_redundant, n_repeated)\n",
    "X, Y = make_multilabel_classification(\n",
    "    n_samples=n_samples,\n",
    "    n_features=n_features,\n",
    "    n_classes=n_classes,\n",
    "    n_labels=n_labels,\n",
    "    random_state=42  # Seed for reproducibility\n",
    ")\n",
    "\n",
    "print(\"Shape of X (features):\", X.shape)\n",
    "print(\"Shape of Y (targets):\", Y.shape)\n",
    "\n",
    "print(\"\\nFirst 5 rows of X (features):\\n\", X[:5])\n",
    "print(\"\\nFirst 5 rows of Y (targets):\\n\", Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "85ec4ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted summary information:\n",
      "feature_0: {'type': 'numeric', 'mean': np.float64(21.826031135758775), 'std': np.float64(32.31977684677651)}\n",
      "feature_1: {'type': 'numeric', 'mean': np.float64(19.496691215824345), 'std': np.float64(32.9567902305616)}\n",
      "feature_2: {'type': 'numeric', 'mean': np.float64(20.85270647844083), 'std': np.float64(32.65031264275359)}\n",
      "feature_3: {'type': 'numeric', 'mean': np.float64(19.819411370962296), 'std': np.float64(32.865869891108325)}\n",
      "feature_4: {'type': 'numeric', 'mean': np.float64(23.04553115226291), 'std': np.float64(32.067311742050975)}\n",
      "target: {'type': 'categorical', 'labels': [nan, 10, np.int64(100), 'class_0'], 'probs': [0.6363636363636364, 0.18181818181818182, 0.09090909090909091, 0.09090909090909091]}\n",
      "cat_feature_0: {'type': 'categorical', 'labels': [nan, np.int64(100), 5, 'D', np.int64(23)], 'probs': [0.6363636363636364, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091]}\n",
      "cat_feature_1: {'type': 'categorical', 'labels': [nan, np.int64(100), 5, 'C', np.int64(25)], 'probs': [0.6363636363636364, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091]}\n",
      "cat_feature_2: {'type': 'categorical', 'labels': [nan, np.int64(100), 5, 'C', np.int64(24)], 'probs': [0.6363636363636364, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091]}\n",
      "cat_feature_3: {'type': 'categorical', 'labels': [nan, np.int64(100), 5, 'A', np.int64(24)], 'probs': [0.6363636363636364, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091]}\n",
      "cat_feature_4: {'type': 'categorical', 'labels': [nan, np.int64(100), 5, 'A', np.int64(28)], 'probs': [0.6363636363636364, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091]}\n",
      "\n",
      "Synthetic dataset generated:\n",
      "    feature_0  feature_1   feature_2  feature_3  feature_4   target  \\\n",
      "0   65.815994  15.923019   32.335230  15.827540  52.242633      nan   \n",
      "1    1.931717  23.661521   18.603929 -25.576096 -14.959926      nan   \n",
      "2   61.931301 -37.665505   21.643047  49.225119   9.833713      nan   \n",
      "3   23.912436  86.494933  -35.164090  -9.875298   7.886955      nan   \n",
      "4   37.654547  69.322227    9.098831  26.086373 -16.245434      nan   \n",
      "5   27.264825  79.910387   39.501486 -39.682906  10.378634      100   \n",
      "6   27.396382   0.921561   28.715742   4.488820  36.907155  class_0   \n",
      "7   19.643682   5.222731  -31.217539  81.071407  55.049209      nan   \n",
      "8   24.596648  93.927362   19.534562  36.544374  32.794029  class_0   \n",
      "9    3.383079 -13.003580   17.593262  24.244299 -61.929883      nan   \n",
      "10 -16.449547  15.580015   34.728532  17.970403  -7.479355      nan   \n",
      "11  62.901775 -62.588457  -30.117182 -61.594546   0.301269  class_0   \n",
      "12  27.025460   7.104874    2.727727  -6.057618  13.227711  class_0   \n",
      "13  20.796209  17.587389   48.898914  43.382315  36.864570       10   \n",
      "14   8.046249  57.570717   29.098037  34.465949  47.431351       10   \n",
      "15  13.915482 -14.006264   44.941798 -11.982031   9.961328      nan   \n",
      "16  31.703378  -8.399528   10.148025  -3.492865  24.179679       10   \n",
      "17  43.776879   4.544049   -9.372339  27.765831  14.943897       10   \n",
      "18  71.049544  48.737658  124.589444  18.476637  16.081173      nan   \n",
      "19  47.467413  50.287185  -19.624013  21.759386  30.369937      100   \n",
      "\n",
      "   cat_feature_0 cat_feature_1 cat_feature_2 cat_feature_3 cat_feature_4  \n",
      "0            nan            25           nan            24           nan  \n",
      "1            nan           nan           nan           nan           nan  \n",
      "2              D           nan           nan             A           nan  \n",
      "3            nan           nan           nan           nan           nan  \n",
      "4            nan           nan           nan            24           nan  \n",
      "5            100           nan            24             5             A  \n",
      "6            nan           100            24           nan           nan  \n",
      "7            nan           nan           nan           nan           nan  \n",
      "8            nan           nan           nan            24            28  \n",
      "9            nan           nan           nan             5           nan  \n",
      "10             5             C           nan           nan            28  \n",
      "11             D           100           nan           nan           nan  \n",
      "12           nan           nan           nan           nan           nan  \n",
      "13           nan           nan             C           nan             5  \n",
      "14           100           nan           nan           nan            28  \n",
      "15           nan             5           nan           nan           nan  \n",
      "16           100           nan           100           nan           nan  \n",
      "17           nan            25           nan           nan           nan  \n",
      "18           100           nan           nan             5           nan  \n",
      "19           nan           nan             C           nan             5  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(n_features)])\n",
    "df['target'] = [f'class_{i}' for i in range(n_classes)] * (n_samples // n_classes) + ['class_0'] * (n_samples % n_classes)\n",
    "df['target'] = df['target'].astype('category')\n",
    "# Add some categorical features\n",
    "for i in range(5 ):# Adding 5 categorical features):\n",
    "    df[f'cat_feature_{i}'] = np.random.choice(['A', 'B', 'C','D','E'], size=n_samples)\n",
    "df_original = df.describe(include='all')\n",
    "\n",
    "\n",
    "summary_info = extract_summary_info(df_original)\n",
    "print(\"Extracted summary information:\")\n",
    "for col, info in summary_info.items():\n",
    "    print(f\"{col}: {info}\")\n",
    "\n",
    "synthetic_df = generate_synthetic_from_summary(summary_info, n=20)\n",
    "print(\"\\nSynthetic dataset generated:\")\n",
    "print(synthetic_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
